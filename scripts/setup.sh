#!/bin/bash
#
# SentinelAI Setup Script
# Installs and configures the complete local LLM stack
#

set -e

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘           SentinelAI - Setup Script                           â•‘"
echo "â•‘           DSGVO-konformes lokales KI-System                   â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Check if running as root
if [ "$EUID" -eq 0 ]; then
    echo -e "${YELLOW}âš  Running as root. Consider running as regular user.${NC}"
fi

# Detect OS
OS="unknown"
if [ -f /etc/os-release ]; then
    . /etc/os-release
    OS=$ID
fi

echo "ğŸ“‹ Detected OS: $OS"
echo ""

# ============== CHECK PREREQUISITES ==============

echo "ğŸ” Checking prerequisites..."

# Check Docker
if command -v docker &> /dev/null; then
    echo -e "${GREEN}âœ“ Docker installed${NC}"
    docker --version
else
    echo -e "${RED}âœ— Docker not found${NC}"
    echo "  Please install Docker: https://docs.docker.com/get-docker/"
    exit 1
fi

# Check Docker Compose
if docker compose version &> /dev/null; then
    echo -e "${GREEN}âœ“ Docker Compose installed${NC}"
    docker compose version
else
    echo -e "${RED}âœ— Docker Compose not found${NC}"
    echo "  Please install Docker Compose: https://docs.docker.com/compose/install/"
    exit 1
fi

# Check NVIDIA GPU
if command -v nvidia-smi &> /dev/null; then
    echo -e "${GREEN}âœ“ NVIDIA GPU detected${NC}"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
else
    echo -e "${YELLOW}âš  NVIDIA GPU not detected - LLM will run on CPU (slow)${NC}"
fi

# Check NVIDIA Container Toolkit
if docker info 2>/dev/null | grep -q "Runtimes.*nvidia"; then
    echo -e "${GREEN}âœ“ NVIDIA Container Toolkit installed${NC}"
else
    echo -e "${YELLOW}âš  NVIDIA Container Toolkit not detected${NC}"
    echo "  For GPU acceleration, install: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"
fi

echo ""

# ============== CREATE DIRECTORIES ==============

echo "ğŸ“ Creating data directories..."
mkdir -p data/vectorstore
mkdir -p data/documents
mkdir -p data/audit
echo -e "${GREEN}âœ“ Directories created${NC}"
echo ""

# ============== SETUP OLLAMA ==============

echo "ğŸš€ Setting up Ollama..."

# Start Ollama container first
docker compose up -d ollama

echo "â³ Waiting for Ollama to start..."
sleep 10

# Pull required models
echo "ğŸ“¥ Downloading Mistral NeMo 12B (this may take a while)..."
docker compose exec ollama ollama pull mistral-nemo:12b-instruct-2407-q4_K_M || {
    echo -e "${YELLOW}âš  Could not pull optimized model, trying default...${NC}"
    docker compose exec ollama ollama pull mistral-nemo || {
        echo -e "${RED}Failed to pull Mistral NeMo. Please run manually:${NC}"
        echo "  docker compose exec ollama ollama pull mistral-nemo"
    }
}

echo "ğŸ“¥ Downloading embedding model..."
docker compose exec ollama ollama pull nomic-embed-text

echo -e "${GREEN}âœ“ Models downloaded${NC}"
echo ""

# ============== BUILD AND START SERVICES ==============

echo "ğŸ”¨ Building and starting all services..."
docker compose build
docker compose up -d

echo ""
echo "â³ Waiting for services to be ready..."
sleep 15

# ============== HEALTH CHECK ==============

echo "ğŸ¥ Running health checks..."

# Check backend
if curl -s http://localhost:8000/health | grep -q "healthy\|degraded"; then
    echo -e "${GREEN}âœ“ Backend is running${NC}"
else
    echo -e "${YELLOW}âš  Backend not responding yet - may still be initializing${NC}"
fi

# Check Ollama
if curl -s http://localhost:11434/api/tags | grep -q "models"; then
    echo -e "${GREEN}âœ“ Ollama is running${NC}"
else
    echo -e "${YELLOW}âš  Ollama not responding${NC}"
fi

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                    Setup Complete! ğŸ‰                         â•‘"
echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
echo "â•‘                                                               â•‘"
echo "â•‘  Services:                                                    â•‘"
echo "â•‘    Backend API:  http://localhost:8000                        â•‘"
echo "â•‘    API Docs:     http://localhost:8000/docs                   â•‘"
echo "â•‘    Ollama:       http://localhost:11434                       â•‘"
echo "â•‘                                                               â•‘"
echo "â•‘  Commands:                                                    â•‘"
echo "â•‘    Start:        docker compose up -d                         â•‘"
echo "â•‘    Stop:         docker compose down                          â•‘"
echo "â•‘    Logs:         docker compose logs -f                       â•‘"
echo "â•‘    Shell:        docker compose exec backend bash             â•‘"
echo "â•‘                                                               â•‘"
echo "â•‘  Frontend (development):                                      â•‘"
echo "â•‘    cd SentinelAi && npm install && npm run dev                â•‘"
echo "â•‘                                                               â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ’¡ Tip: Run 'docker compose logs -f' to monitor the services"
