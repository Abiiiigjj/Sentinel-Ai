# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
LLM_MODEL=mistral-nemo:12b-instruct-2407-q4_K_M
EMBEDDING_MODEL=nomic-embed-text

# Data Storage
DATA_DIR=./data
VECTOR_STORE_DIR=./data/vectorstore
DOCUMENTS_DIR=./data/documents
AUDIT_LOG_DIR=./data/audit

# PII Detection
PII_DETECTION_ENABLED=true
SPACY_MODEL=de_core_news_lg

# Server
HOST=0.0.0.0
PORT=8000
DEBUG=false

# Frontend (Vite)
VITE_API_URL=http://localhost:8000
